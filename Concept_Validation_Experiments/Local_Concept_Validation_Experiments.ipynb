{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7ad9fa5",
   "metadata": {},
   "source": [
    "# Concept Validation Experiment - Local Setup\n",
    "\n",
    "This notebook is adapted to run on your local machine with the ConceptVectors repository.\n",
    "It validates that concept vectors correctly encode specific knowledge by adding noise to them and measuring the impact on model outputs.\n",
    "\n",
    "**Updated**: Now includes support for the lightweight Gemma-1.1-1b-it model for local execution.\n",
    "\n",
    "## 🚀 Quick Start Instructions\n",
    "\n",
    "**Prerequisites**: Virtual environment with dependencies is already active ✅\n",
    "\n",
    "### Steps to Run:\n",
    "1. **Run cells 1-5**: Setup and load dependencies\n",
    "2. **Run cell 6**: System capability assessment (shows your hardware specs)\n",
    "3. **Run cell 7**: Configuration (auto-selects best model for your system)\n",
    "4. **Run cells 8-11**: Utility functions\n",
    "5. **Run cell 12**: Load Gemma model (takes 1-2 minutes)\n",
    "6. **Run cell 13**: Create synthetic test concepts\n",
    "7. **Run cell 14**: Run the validation experiment (takes 5-10 minutes)\n",
    "8. **Run cells 15-16**: Analyze results and create visualizations\n",
    "\n",
    "**Expected Runtime**: 10-15 minutes total\n",
    "**Memory Usage**: 1-4 GB depending on your system\n",
    "**Output**: Results saved as JSON and PNG files in your ConceptVectors folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d22cdf",
   "metadata": {},
   "source": [
    "## Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa4e1160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK BLEU available\n"
     ]
    }
   ],
   "source": [
    "# Check NLTK data availability\n",
    "import nltk\n",
    "try:\n",
    "    from nltk.translate.bleu_score import sentence_bleu\n",
    "    print(\"NLTK BLEU available\")\n",
    "except:\n",
    "    print(\"Downloading NLTK data...\")\n",
    "    nltk.download('punkt')\n",
    "    from nltk.translate.bleu_score import sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ac5d7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found. Using CPU.\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check GPU availability\n",
    "if torch.cuda.is_available():\n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    print(f\"Found {gpu_count} GPU device(s):\")\n",
    "    for i in range(gpu_count):\n",
    "        gpu_name = torch.cuda.get_device_name(i)\n",
    "        print(f\"  GPU {i + 1}: {gpu_name}\")\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    print(\"No GPU found. Using CPU.\")\n",
    "    device = 'cpu'\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0712980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All dependencies loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge import Rouge\n",
    "import statistics\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "random.seed(8888)\n",
    "torch.manual_seed(8888)\n",
    "np.random.seed(8888)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(8888)\n",
    "    torch.cuda.manual_seed_all(8888)\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "tqdm.pandas()\n",
    "\n",
    "print(\"All dependencies loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c5061d",
   "metadata": {},
   "source": [
    "## System Capability Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3cdbdc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SYSTEM CAPABILITY ASSESSMENT ===\n",
      "Platform: macOS-15.3.2-arm64-arm-64bit\n",
      "Processor: arm\n",
      "CPU Cores: 8 logical, 8 physical\n",
      "Total RAM: 16.0 GB\n",
      "Available RAM: 5.08 GB (31.7% free)\n",
      "\n",
      "💻 No GPU detected - using CPU only\n",
      "\n",
      "✅ RAM OK: Can run Gemma-1B on CPU with full precision\n",
      "\n",
      "📊 EXPERIMENT RECOMMENDATIONS:\n",
      "\n",
      "🎯 SUGGESTED CONFIGURATION:\n",
      "  • Model: Gemma-1.1-1B-it with bfloat16 on CPU\n",
      "  • Sample size: Start with 3 concepts\n",
      "  • Expected runtime: ~10-20 minutes for 3 concepts\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "import platform\n",
    "import subprocess\n",
    "\n",
    "def get_system_info():\n",
    "    \"\"\"Get comprehensive system information\"\"\"\n",
    "    info = {}\n",
    "    \n",
    "    # Basic system info\n",
    "    info['platform'] = platform.platform()\n",
    "    info['machine'] = platform.machine()\n",
    "    info['processor'] = platform.processor()\n",
    "    \n",
    "    # Memory info\n",
    "    memory = psutil.virtual_memory()\n",
    "    info['total_ram_gb'] = round(memory.total / (1024**3), 2)\n",
    "    info['available_ram_gb'] = round(memory.available / (1024**3), 2)\n",
    "    info['ram_usage_percent'] = memory.percent\n",
    "    \n",
    "    # CPU info\n",
    "    info['cpu_count'] = psutil.cpu_count()\n",
    "    info['cpu_count_physical'] = psutil.cpu_count(logical=False)\n",
    "    \n",
    "    # GPU info\n",
    "    info['gpu_available'] = torch.cuda.is_available()\n",
    "    if info['gpu_available']:\n",
    "        info['gpu_count'] = torch.cuda.device_count()\n",
    "        info['gpu_names'] = [torch.cuda.get_device_name(i) for i in range(torch.cuda.device_count())]\n",
    "        # Get GPU memory for each device\n",
    "        info['gpu_memory_gb'] = []\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            props = torch.cuda.get_device_properties(i)\n",
    "            total_memory = props.total_memory / (1024**3)\n",
    "            info['gpu_memory_gb'].append(round(total_memory, 2))\n",
    "    else:\n",
    "        info['gpu_count'] = 0\n",
    "        info['gpu_names'] = []\n",
    "        info['gpu_memory_gb'] = []\n",
    "    \n",
    "    return info\n",
    "\n",
    "def assess_capability(info):\n",
    "    \"\"\"Assess if system can handle the experiment\"\"\"\n",
    "    recommendations = []\n",
    "    warnings = []\n",
    "    \n",
    "    # Model memory requirements (approximate)\n",
    "    model_memory_requirements = {\n",
    "        'llama_7b': {\n",
    "            'fp32': 28,  # GB\n",
    "            'fp16': 14,  # GB\n",
    "            'bfloat16': 14,  # GB\n",
    "            'int8': 7,   # GB\n",
    "            'int4': 4    # GB\n",
    "        },\n",
    "        'gemma_1b': {\n",
    "            'fp32': 3.5,  # GB\n",
    "            'fp16': 2.0,\n",
    "            'bfloat16': 2.0,\n",
    "            'int8': 1.0,\n",
    "            'int4': 0.7\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(\"=== SYSTEM CAPABILITY ASSESSMENT ===\")\n",
    "    print(f\"Platform: {info['platform']}\")\n",
    "    print(f\"Processor: {info['processor']}\")\n",
    "    print(f\"CPU Cores: {info['cpu_count']} logical, {info['cpu_count_physical']} physical\")\n",
    "    print(f\"Total RAM: {info['total_ram_gb']} GB\")\n",
    "    print(f\"Available RAM: {info['available_ram_gb']} GB ({100-info['ram_usage_percent']:.1f}% free)\")\n",
    "    \n",
    "    if info['gpu_available']:\n",
    "        print(f\"\\n🎮 GPU Information:\")\n",
    "        for i, (name, memory) in enumerate(zip(info['gpu_names'], info['gpu_memory_gb'])):\n",
    "            print(f\"  GPU {i}: {name} ({memory} GB VRAM)\")\n",
    "        \n",
    "        # GPU recommendations\n",
    "        max_gpu_memory = max(info['gpu_memory_gb']) if info['gpu_memory_gb'] else 0\n",
    "    else:\n",
    "        print(f\"\\n💻 No GPU detected - using CPU only\")\n",
    "        max_gpu_memory = 0\n",
    "\n",
    "    # Check Gemma-1B capability\n",
    "    if max_gpu_memory >= model_memory_requirements['gemma_1b']['bfloat16']:\n",
    "        print(f\"\\n✅ GPU BASIC: Can run Gemma-1B with bfloat16 precision\")\n",
    "        recommendations.append(\"Use GPU with Gemma-1B model if limited on memory\")\n",
    "    elif max_gpu_memory >= model_memory_requirements['gemma_1b']['int8']:\n",
    "        print(f\"\\n✅ GPU MINIMAL: Can run Gemma-1B with 8-bit quantization\")\n",
    "        recommendations.append(\"Use GPU with Gemma-1B and 8-bit quantization\")\n",
    "        \n",
    "        # Check LLaMA-7B capability\n",
    "        if max_gpu_memory >= model_memory_requirements['llama_7b']['bfloat16']:\n",
    "            print(f\"✅ GPU can also run LLaMA-7B with bfloat16 precision\")\n",
    "        elif max_gpu_memory >= model_memory_requirements['llama_7b']['int8']:\n",
    "            print(f\"⚠️  GPU can run LLaMA-7B with 8-bit quantization\")\n",
    "        else:\n",
    "            print(f\"❌ GPU insufficient for LLaMA-7B - stick with Gemma-1B\")\n",
    "    elif max_gpu_memory >= model_memory_requirements['gemma_1b']['int8']:\n",
    "        print(f\"\\n✅ GPU MINIMAL: Can run Gemma-1B with 8-bit quantization\")\n",
    "        recommendations.append(\"Use GPU with Gemma-1B and 8-bit quantization\")\n",
    "        \n",
    "        # Check LLaMA-7B capability\n",
    "        if max_gpu_memory >= model_memory_requirements['llama_7b']['bfloat16']:\n",
    "            print(f\"✅ GPU can also run LLaMA-7B with bfloat16 precision\")\n",
    "        elif max_gpu_memory >= model_memory_requirements['llama_7b']['int8']:\n",
    "            print(f\"⚠️  GPU can run LLaMA-7B with 8-bit quantization\")\n",
    "        else:\n",
    "            print(f\"❌ GPU insufficient for LLaMA-7B - stick with Gemma-1B\")\n",
    "        \n",
    "    if info['available_ram_gb'] >= model_memory_requirements['gemma_1b']['fp32']:\n",
    "        print(f\"\\n✅ RAM OK: Can run Gemma-1B on CPU with full precision\")\n",
    "    elif info['available_ram_gb'] >= model_memory_requirements['gemma_1b']['bfloat16']:\n",
    "        print(f\"\\n✅ RAM OK: Can run Gemma-1B on CPU with reduced precision\")\n",
    "    elif info['available_ram_gb'] >= model_memory_requirements['gemma_1b']['int8']:\n",
    "        print(f\"\\n⚠️  RAM LOW: Run Gemma-1B on CPU with 8-bit quantization\")\n",
    "    else:\n",
    "        print(f\"\\n❌ RAM INSUFFICIENT: Not suitable even for Gemma-1B\")\n",
    "\n",
    "    \n",
    "    # Experiment scope recommendations\n",
    "    print(f\"\\n📊 EXPERIMENT RECOMMENDATIONS:\")\n",
    "    for rec in recommendations:\n",
    "        print(f\"  • {rec}\")\n",
    "    \n",
    "    if warnings:\n",
    "        print(f\"\\n⚠️  WARNINGS:\")\n",
    "        for warning in warnings:\n",
    "            print(f\"  • {warning}\")\n",
    "    \n",
    "    # Specific recommendations based on capability\n",
    "    print(f\"\\n🎯 SUGGESTED CONFIGURATION:\")\n",
    "    if info['gpu_available'] and max_gpu_memory >= 2:\n",
    "        print(f\"  • Model: Gemma-1.1-1B-it with bfloat16 on GPU (RECOMMENDED)\")\n",
    "        print(f\"  • Sample size: Can handle full dataset\")\n",
    "        print(f\"  • Expected runtime: ~2-5 minutes for 3 concepts\")\n",
    "        if max_gpu_memory >= 14:\n",
    "            print(f\"  • Also try: LLaMA-7B if you want higher quality responses\")\n",
    "    elif info['gpu_available'] and max_gpu_memory >= 1:\n",
    "        print(f\"  • Model: Gemma-1.1-1B-it with 8-bit quantization on GPU\")\n",
    "        print(f\"  • Sample size: Can handle full dataset\")\n",
    "        print(f\"  • Expected runtime: ~3-7 minutes for 3 concepts\")\n",
    "    elif info['available_ram_gb'] >= 4:\n",
    "        print(f\"  • Model: Gemma-1.1-1B-it with bfloat16 on CPU\")\n",
    "        print(f\"  • Sample size: Start with 3 concepts\")\n",
    "        print(f\"  • Expected runtime: ~10-20 minutes for 3 concepts\")\n",
    "    elif info['available_ram_gb'] >= 2:\n",
    "        print(f\"  • Model: Gemma-1.1-1B-it with 8-bit quantization on CPU\")\n",
    "        print(f\"  • Sample size: Start with 3 concepts\")\n",
    "        print(f\"  • Expected runtime: ~15-30 minutes for 3 concepts\")\n",
    "    else:\n",
    "        print(f\"  • Model: Consider using cloud service or smaller model\")\n",
    "        print(f\"  • Alternative: Use Hugging Face Inference API\")\n",
    "        print(f\"  • Sample size: Not recommended for local execution\")\n",
    "    \n",
    "    return recommendations, warnings\n",
    "\n",
    "# Run the assessment\n",
    "system_info = get_system_info()\n",
    "recommendations, warnings = assess_capability(system_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395ab8f6",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9361aa54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  Selected model: google/gemma-3-1b-it (light version for limited system)\n",
      "Base directory: /Users/daniel/Desktop/ConceptVectors\n",
      "Data directory: /Users/daniel/Desktop/ConceptVectors/ConceptVectors_data\n",
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Configuration - Update these paths as needed\n",
    "BASE_DIR = '/Users/daniel/Desktop/ConceptVectors'\n",
    "DATA_DIR = os.path.join(BASE_DIR, 'ConceptVectors_data')\n",
    "\n",
    "# Model configuration\n",
    "# Lightweight model - recommended for local execution\n",
    "GEMMA_MODEL_NAME = \"google/gemma-3-1b-it\"  # Gemma-1.1 1B Instruct\n",
    "\n",
    "# Larger models - use if system has sufficient resources\n",
    "LLAMA_MODEL_NAME = \"meta-llama/Llama-2-7b-chat-hf\"  # Requires HF access\n",
    "OLMO_MODEL_NAME = \"allenai/OLMo-7B\"\n",
    "\n",
    "# Model selection based on system capability\n",
    "max_gpu_memory = max(system_info['gpu_memory_gb']) if system_info['gpu_available'] and system_info['gpu_memory_gb'] else 0\n",
    "available_ram = system_info['available_ram_gb']\n",
    "\n",
    "# Auto-select best model for system\n",
    "if max_gpu_memory >= 6 or available_ram >= 6:\n",
    "    SELECTED_MODEL = GEMMA_MODEL_NAME\n",
    "    print(f\"✓ Selected model: {SELECTED_MODEL} (recommended for this system)\")\n",
    "elif max_gpu_memory >= 2 or available_ram >= 2:\n",
    "    SELECTED_MODEL = GEMMA_MODEL_NAME\n",
    "    print(f\"⚠️  Selected model: {SELECTED_MODEL} (light version for limited system)\")\n",
    "elif max_gpu_memory >= 14 or available_ram >= 14:\n",
    "    SELECTED_MODEL = LLAMA_MODEL_NAME\n",
    "    print(f\"✓ Selected model: {SELECTED_MODEL} (larger model, good system detected)\")\n",
    "else:\n",
    "    SELECTED_MODEL = GEMMA_MODEL_NAME\n",
    "    print(f\"❌ Fallback to: {SELECTED_MODEL} (low resources, performance may be degraded)\")\n",
    "\n",
    "\n",
    "# Experiment settings\n",
    "NOISE_SCALE = 0.1  # Amount of noise to add to concept vectors\n",
    "MAX_NEW_TOKENS = 100  # Max tokens to generate\n",
    "DEVICE = device\n",
    "\n",
    "print(f\"Base directory: {BASE_DIR}\")\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc855ce",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e135759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metrics\n",
    "def calculate_bleu(reference, candidate):\n",
    "    \"\"\"Calculate BLEU score between reference and candidate text\"\"\"\n",
    "    if not reference.strip() or not candidate.strip():\n",
    "        return 0.0\n",
    "    reference = [reference.split()]\n",
    "    candidate = candidate.split()\n",
    "    cc = SmoothingFunction()\n",
    "    bleu_score = sentence_bleu(reference, candidate, smoothing_function=cc.method3)\n",
    "    return bleu_score\n",
    "\n",
    "def calculate_rouge_l(reference, candidate):\n",
    "    \"\"\"Calculate ROUGE-L score between reference and candidate text\"\"\"\n",
    "    try:\n",
    "        if not reference.strip() or not candidate.strip():\n",
    "            return 0.0\n",
    "        rouge = Rouge()\n",
    "        scores = rouge.get_scores(candidate, reference)\n",
    "        rouge_l_score = scores[0]['rouge-l']['f']\n",
    "        return rouge_l_score\n",
    "    except Exception as e:\n",
    "        print(f\"ROUGE calculation error: {e}\")\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee901e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(model, location, noise_scale=0):\n",
    "    \"\"\"Add Gaussian noise to specific concept vector dimension\"\"\"\n",
    "    if noise_scale == 0:\n",
    "        return\n",
    "        \n",
    "    # Get model architecture info\n",
    "    model_type = model.config.model_type.lower()\n",
    "    \n",
    "    # Determine hidden size based on model\n",
    "    if hasattr(model.config, 'hidden_size'):\n",
    "        hidden_size = model.config.hidden_size\n",
    "    elif hasattr(model.config, 'd_model'):\n",
    "        hidden_size = model.config.d_model\n",
    "    else:\n",
    "        hidden_size = 2048  # Default for smaller models\n",
    "    \n",
    "    # Create Gaussian noise\n",
    "    mean = 0\n",
    "    std = noise_scale\n",
    "    shape = (hidden_size,)\n",
    "    \n",
    "    noise = torch.normal(mean, std, size=shape).to(model.device)\n",
    "    dimension, layer = location[0], location[1]\n",
    "    \n",
    "    # Apply noise based on model architecture\n",
    "    if 'llama' in model_type:\n",
    "        param_name = f'model.layers.{layer}.mlp.down_proj.weight'\n",
    "        if param_name in model.state_dict():\n",
    "            model.state_dict()[param_name][:, dimension] += noise\n",
    "    elif 'olmo' in model_type:\n",
    "        param_name = f'model.transformer.blocks.{layer}.ff_out.weight'\n",
    "        if param_name in model.state_dict():\n",
    "            model.state_dict()[param_name][:, dimension] += noise\n",
    "    elif 'gemma' in model_type:\n",
    "        # Gemma architecture - adjust parameter path\n",
    "        param_name = f'model.layers.{layer}.mlp.down_proj.weight'\n",
    "        if param_name in model.state_dict():\n",
    "            model.state_dict()[param_name][:, dimension] += noise\n",
    "        else:\n",
    "            # Alternative parameter naming\n",
    "            param_name = f'model.layers.{layer}.feed_forward.down_proj.weight'\n",
    "            if param_name in model.state_dict():\n",
    "                model.state_dict()[param_name][:, dimension] += noise\n",
    "    else:\n",
    "        print(f\"Unknown model type: {model_type}\")\n",
    "        print(\"Available layer names:\")\n",
    "        for name in list(model.state_dict().keys())[:10]:  # Show first 10\n",
    "            print(f\"  {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7ad71e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answers(model, tokenizer, questions, noise_scale=0, location=None):\n",
    "    \"\"\"Generate answers for given questions, optionally with noise added to concept vector\"\"\"\n",
    "    # Save original state\n",
    "    if noise_scale > 0 and location is not None:\n",
    "        original_state = copy.deepcopy(model.state_dict())\n",
    "        add_noise(model, location, noise_scale)\n",
    "    \n",
    "    # Format questions\n",
    "    formatted_questions = []\n",
    "    for question in questions:\n",
    "        formatted_questions.append(f\"Question: {question}\\nAnswer:\")\n",
    "    \n",
    "    # Tokenize and generate\n",
    "    inputs = tokenizer(formatted_questions, return_tensors=\"pt\", padding=True, \n",
    "                      return_token_type_ids=False).to(model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        generation_output = model.generate(\n",
    "            **inputs,\n",
    "            do_sample=False,\n",
    "            max_new_tokens=MAX_NEW_TOKENS,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    # Decode only the new tokens\n",
    "    answers = []\n",
    "    for i, output in enumerate(generation_output):\n",
    "        input_length = len(inputs['input_ids'][i])\n",
    "        new_tokens = output[input_length:]\n",
    "        answer = tokenizer.decode(new_tokens, skip_special_tokens=True)\n",
    "        answers.append(answer.strip())\n",
    "    \n",
    "    # Restore original state if noise was added\n",
    "    if noise_scale > 0 and location is not None:\n",
    "        model.load_state_dict(original_state)\n",
    "    \n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f2e1aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_select_except(lst, n, exclude_index):\n",
    "    \"\"\"Randomly select n elements from list, excluding element at exclude_index\"\"\"\n",
    "    # Exclude the element at the specified position\n",
    "    candidates = [elem for i, elem in enumerate(lst) if i != exclude_index]\n",
    "    # Randomly select n elements from the candidate elements\n",
    "    if len(candidates) < n:\n",
    "        return candidates\n",
    "    selected = random.sample(candidates, n)\n",
    "    return selected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a6bd76",
   "metadata": {},
   "source": [
    "## Load and Test with Gemma Model (Recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec68520f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Gemma model: google/gemma-3-1b-it\n",
      "This should be quick for the lightweight model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2683d56ddf694686b4987b90c5cd0a62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12538e1052964a45b75c9f98047caf9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/215 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d856d80431134d2080201db5bcd20833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.16M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d5506048755491d9b70dd16786cda52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.69M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d3c023c829444c986d329c1b09e5d7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1311a6312fcf4052824b4d195b7d4da6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/35.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51e8933625d44ac0bde3013f6b8a25f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Gemma model loaded successfully on cpu\n",
      "Model type: gemma3_text\n",
      "Hidden size: 1152\n",
      "Number of layers: 26\n",
      "\n",
      "🧪 Test generation:\n",
      "Input: What is the capital of France?\n",
      "Output: What is the capital of France?\n",
      "\n",
      "The capital of France is Paris.\n",
      "\n",
      "Final Answer: The final answer is $\\boxed{Paris\n",
      "\n",
      "🧪 Test generation:\n",
      "Input: What is the capital of France?\n",
      "Output: What is the capital of France?\n",
      "\n",
      "The capital of France is Paris.\n",
      "\n",
      "Final Answer: The final answer is $\\boxed{Paris\n"
     ]
    }
   ],
   "source": [
    "# Load Gemma model and tokenizer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from huggingface_hub import login\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Set transformers verbosity to reduce warnings\n",
    "os.environ['TRANSFORMERS_VERBOSITY'] = 'error'\n",
    "\n",
    "# Authenticate with Hugging Face\n",
    "login(\"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\")\n",
    "\n",
    "print(f\"Loading Gemma model: {GEMMA_MODEL_NAME}\")\n",
    "print(\"This should be quick for the lightweight model...\")\n",
    "\n",
    "try:\n",
    "    # Determine precision based on system capability\n",
    "    if DEVICE == 'cuda' and max_gpu_memory >= 6:\n",
    "        torch_dtype = torch.bfloat16\n",
    "    elif DEVICE == 'cuda' and max_gpu_memory >= 3:\n",
    "        torch_dtype = torch.bfloat16\n",
    "    elif DEVICE == 'cuda':\n",
    "        torch_dtype = torch.float16\n",
    "    else:\n",
    "        torch_dtype = torch.float32  # Use full precision on CPU\n",
    "\n",
    "    # Load model and tokenizer\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        GEMMA_MODEL_NAME,\n",
    "        torch_dtype=torch_dtype,\n",
    "        device_map='auto' if DEVICE == 'cuda' else None\n",
    "    )\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(GEMMA_MODEL_NAME)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.padding_side = \"left\"\n",
    "\n",
    "    if DEVICE == 'cpu':\n",
    "        model = model.to('cpu')\n",
    "\n",
    "    print(f\"✓ Gemma model loaded successfully on {model.device}\")\n",
    "    print(f\"Model type: {model.config.model_type}\")\n",
    "    print(f\"Hidden size: {getattr(model.config, 'hidden_size', 'Unknown')}\")\n",
    "    print(f\"Number of layers: {getattr(model.config, 'num_hidden_layers', 'Unknown')}\")\n",
    "\n",
    "    # Test generation\n",
    "    test_input = \"What is the capital of France?\"\n",
    "    inputs = tokenizer(test_input, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs, \n",
    "            max_new_tokens=10, \n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    # Decode only the new tokens (response)\n",
    "    input_length = len(inputs['input_ids'][0])\n",
    "    new_tokens = outputs[0][input_length:]\n",
    "    test_response = tokenizer.decode(new_tokens, skip_special_tokens=True).strip()\n",
    "    \n",
    "    print(f\"\\n🧪 Test generation:\")\n",
    "    print(f\"Input: {test_input}\")\n",
    "    print(f\"Response: {test_response}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading Gemma model: {e}\")\n",
    "    print(\"Make sure Transformers is up to date: pip install --upgrade transformers\")\n",
    "    model = None\n",
    "    tokenizer = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cbb9acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧪 Test generation:\n",
      "Input: What is the capital of France?\n",
      "Response: The capital of France is Paris.\n",
      "\n",
      "Final\n"
     ]
    }
   ],
   "source": [
    " # Test generation\n",
    "test_input = \"What is the capital of France?\"\n",
    "inputs = tokenizer(test_input, return_tensors=\"pt\").to(model.device)\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        **inputs, \n",
    "        max_new_tokens=10, \n",
    "        do_sample=False,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "# Decode only the new tokens (response)\n",
    "input_length = len(inputs['input_ids'][0])\n",
    "new_tokens = outputs[0][input_length:]\n",
    "test_response = tokenizer.decode(new_tokens, skip_special_tokens=True).strip()\n",
    "\n",
    "print(f\"\\n🧪 Test generation:\")\n",
    "print(f\"Input: {test_input}\")\n",
    "print(f\"Response: {test_response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be1a9b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating synthetic concept data for Gemma model testing...\n",
      "✓ Created 3 synthetic concepts for testing\n",
      "Model has 26 layers, hidden size 1152\n"
     ]
    }
   ],
   "source": [
    "# Create synthetic concept data for Gemma model testing\n",
    "# Since we don't have pre-computed concept vectors for Gemma, we'll use synthetic data\n",
    "if model is not None:\n",
    "    print(\"Creating synthetic concept data for Gemma model testing...\")\n",
    "    \n",
    "    # Get model dimensions\n",
    "    num_layers = getattr(model.config, 'num_hidden_layers', 18)\n",
    "    hidden_size = getattr(model.config, 'hidden_size', 2048)\n",
    "    \n",
    "    # Create test concepts\n",
    "    synthetic_concepts = [\n",
    "        {\n",
    "            \"Concept\": \"Capital Cities\",\n",
    "            \"Layer\": min(8, num_layers-1),\n",
    "            \"Dim\": 100,\n",
    "            \"QA\": [\n",
    "                \"What is the capital of France?\",\n",
    "                \"What is the capital of Germany?\",\n",
    "                \"What is the capital of Japan?\",\n",
    "                \"What is the capital of Australia?\",\n",
    "                \"What is the capital of Brazil?\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"Concept\": \"Basic Math\",\n",
    "            \"Layer\": min(6, num_layers-1),\n",
    "            \"Dim\": 200,\n",
    "            \"QA\": [\n",
    "                \"What is 2 + 2?\",\n",
    "                \"What is 5 * 3?\",\n",
    "                \"What is 10 - 4?\",\n",
    "                \"What is 12 / 3?\",\n",
    "                \"What is 7 + 8?\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"Concept\": \"Colors\",\n",
    "            \"Layer\": min(4, num_layers-1),\n",
    "            \"Dim\": 300,\n",
    "            \"QA\": [\n",
    "                \"What color do you get when you mix red and blue?\",\n",
    "                \"What color do you get when you mix yellow and blue?\",\n",
    "                \"What is the color of grass?\",\n",
    "                \"What is the color of the sun?\",\n",
    "                \"What is the color of snow?\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(f\"✓ Created {len(synthetic_concepts)} synthetic concepts for testing\")\n",
    "    print(f\"Model has {num_layers} layers, hidden size {hidden_size}\")\n",
    "    \n",
    "    # Use synthetic concepts for testing\n",
    "    concepts_list = synthetic_concepts\n",
    "else:\n",
    "    concepts_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438f6f6d",
   "metadata": {},
   "source": [
    "## Run Validation Experiment with Gemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9f4f50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running concept validation experiment with Gemma model...\n",
      "Testing 3 concepts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing concepts:   0%|          | 0/3 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Generating original answers for Capital Cities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Generating perturbed answers for Capital Cities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Processing concepts:  33%|███▎      | 1/3 [02:59<05:59, 179.98s/it]The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Processing concepts:  33%|███▎      | 1/3 [02:59<05:59, 179.98s/it]The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Capital Cities: BLEU=0.283, ROUGE=0.850\n",
      "  Unrelated: BLEU=0.573, ROUGE=0.850\n",
      "  Example - Original: Paris...\n",
      "  Example - Perturbed: Paris...\n",
      "  Generating original answers for Basic Math...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Generating perturbed answers for Basic Math...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Processing concepts:  67%|██████▋   | 2/3 [06:04<03:02, 182.50s/it]The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Processing concepts:  67%|██████▋   | 2/3 [06:04<03:02, 182.50s/it]The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Basic Math: BLEU=0.483, ROUGE=1.000\n",
      "  Unrelated: BLEU=0.573, ROUGE=0.810\n",
      "  Example - Original: 4...\n",
      "  Example - Perturbed: 4...\n",
      "  Generating original answers for Colors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Generating perturbed answers for Colors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Processing concepts: 100%|██████████| 3/3 [07:46<00:00, 155.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Colors: BLEU=0.601, ROUGE=0.647\n",
      "  Unrelated: BLEU=0.295, ROUGE=0.875\n",
      "  Example - Original: Purple\n",
      "\n",
      "---\n",
      "\n",
      "Let's try another one:\n",
      "\n",
      "What color do...\n",
      "  Example - Perturbed: Purple\n",
      "\n",
      "---\n",
      "\n",
      "This is a classic riddle! Let me know...\n",
      "\n",
      "✓ Completed validation on 3 concepts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run validation on Gemma model\n",
    "if model is not None and concepts_list:\n",
    "    print(\"Running concept validation experiment with Gemma model...\")\n",
    "    print(f\"Testing {len(concepts_list)} concepts\")\n",
    "    \n",
    "    gemma_results = []\n",
    "    \n",
    "    for idx, concept in enumerate(tqdm(concepts_list, desc=\"Processing concepts\")):\n",
    "        try:\n",
    "            concept_name = concept['Concept']\n",
    "            dimension, layer = concept['Dim'], concept['Layer']\n",
    "            questions = concept.get('QA', [])\n",
    "            \n",
    "            if not questions:\n",
    "                print(f\"Skipping {concept_name}: No questions found\")\n",
    "                continue\n",
    "            \n",
    "            # Generate unrelated questions from other concepts\n",
    "            unrelated_concepts = random_select_except(concepts_list, 2, idx)\n",
    "            unrelated_questions = []\n",
    "            for uc in unrelated_concepts:\n",
    "                unrelated_questions.extend(uc.get('QA', [])[:3])  # 3 questions each\n",
    "            \n",
    "            # Generate answers without noise (original)\n",
    "            print(f\"  Generating original answers for {concept_name}...\")\n",
    "            original_answers = generate_answers(model, tokenizer, questions)\n",
    "            original_unrelated = generate_answers(model, tokenizer, unrelated_questions)\n",
    "            \n",
    "            # Generate answers with noise (perturbed)\n",
    "            print(f\"  Generating perturbed answers for {concept_name}...\")\n",
    "            perturbed_answers = generate_answers(model, tokenizer, questions, \n",
    "                                              noise_scale=NOISE_SCALE, location=[dimension, layer])\n",
    "            perturbed_unrelated = generate_answers(model, tokenizer, unrelated_questions,\n",
    "                                                noise_scale=NOISE_SCALE, location=[dimension, layer])\n",
    "            \n",
    "            # Calculate scores\n",
    "            bleu_scores = []\n",
    "            rouge_scores = []\n",
    "            unrelated_bleu_scores = []\n",
    "            unrelated_rouge_scores = []\n",
    "            \n",
    "            for orig, pert in zip(original_answers, perturbed_answers):\n",
    "                bleu_scores.append(calculate_bleu(orig, pert))\n",
    "                rouge_scores.append(calculate_rouge_l(orig, pert))\n",
    "            \n",
    "            for orig, pert in zip(original_unrelated, perturbed_unrelated):\n",
    "                unrelated_bleu_scores.append(calculate_bleu(orig, pert))\n",
    "                unrelated_rouge_scores.append(calculate_rouge_l(orig, pert))\n",
    "            \n",
    "            # Calculate mean scores\n",
    "            mean_bleu = statistics.mean(bleu_scores) if bleu_scores else 0\n",
    "            mean_rouge = statistics.mean(rouge_scores) if rouge_scores else 0\n",
    "            mean_unrelated_bleu = statistics.mean(unrelated_bleu_scores) if unrelated_bleu_scores else 0\n",
    "            mean_unrelated_rouge = statistics.mean(unrelated_rouge_scores) if unrelated_rouge_scores else 0\n",
    "            \n",
    "            result = {\n",
    "                'concept': concept_name,\n",
    "                'layer': layer,\n",
    "                'dimension': dimension,\n",
    "                'target_bleu': mean_bleu,\n",
    "                'target_rouge': mean_rouge,\n",
    "                'unrelated_bleu': mean_unrelated_bleu,\n",
    "                'unrelated_rouge': mean_unrelated_rouge,\n",
    "                'model': 'gemma-1.1-1b-it'\n",
    "            }\n",
    "            \n",
    "            gemma_results.append(result)\n",
    "            \n",
    "            print(f\"✓ {concept_name}: BLEU={mean_bleu:.3f}, ROUGE={mean_rouge:.3f}\")\n",
    "            print(f\"  Unrelated: BLEU={mean_unrelated_bleu:.3f}, ROUGE={mean_unrelated_rouge:.3f}\")\n",
    "            \n",
    "            # Show example outputs\n",
    "            if len(original_answers) > 0 and len(perturbed_answers) > 0:\n",
    "                print(f\"  Example - Original: {original_answers[0][:50]}...\")\n",
    "                print(f\"  Example - Perturbed: {perturbed_answers[0][:50]}...\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing {concept.get('Concept', 'Unknown')}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\n✓ Completed validation on {len(gemma_results)} concepts\")\n",
    "else:\n",
    "    print(\"Skipping validation: Model or concept data not available\")\n",
    "    gemma_results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26034c90",
   "metadata": {},
   "source": [
    "## Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fc9d1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CONCEPT VALIDATION RESULTS (GEMMA) ===\n",
      "Model: gemma-1.1-1b-it\n",
      "Number of concepts tested: 3\n",
      "Noise scale: 0.1\n",
      "\n",
      "Mean scores:\n",
      "Target BLEU: 0.456 ± 0.161\n",
      "Target ROUGE: 0.832 ± 0.177\n",
      "Unrelated BLEU: 0.480 ± 0.161\n",
      "Unrelated ROUGE: 0.845 ± 0.033\n",
      "\n",
      "📊 VALIDATION ANALYSIS:\n",
      "Target knowledge degradation: 0.544\n",
      "Unrelated knowledge degradation: 0.520\n",
      "❌ INCONCLUSIVE: No clear evidence of concept-specific encoding.\n",
      "   This could be due to synthetic data or model limitations.\n",
      "\n",
      "Detailed results:\n",
      "Capital Cities (L8, D100):\n",
      "  Target: BLEU=0.283, ROUGE=0.850\n",
      "  Unrelated: BLEU=0.573, ROUGE=0.850\n",
      "Basic Math (L6, D200):\n",
      "  Target: BLEU=0.483, ROUGE=1.000\n",
      "  Unrelated: BLEU=0.573, ROUGE=0.810\n",
      "Colors (L4, D300):\n",
      "  Target: BLEU=0.601, ROUGE=0.647\n",
      "  Unrelated: BLEU=0.295, ROUGE=0.875\n",
      "\n",
      "✓ Results saved to /Users/daniel/Desktop/ConceptVectors/gemma_concept_validation_results.json\n"
     ]
    }
   ],
   "source": [
    "# Analyze results\n",
    "if gemma_results:\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Create results DataFrame\n",
    "    df = pd.DataFrame(gemma_results)\n",
    "    \n",
    "    print(\"=== CONCEPT VALIDATION RESULTS (GEMMA) ===\")\n",
    "    print(f\"Model: {df['model'].iloc[0] if 'model' in df.columns else 'Unknown'}\")\n",
    "    print(f\"Number of concepts tested: {len(df)}\")\n",
    "    print(f\"Noise scale: {NOISE_SCALE}\")\n",
    "    print(\"\\nMean scores:\")\n",
    "    print(f\"Target BLEU: {df['target_bleu'].mean():.3f} ± {df['target_bleu'].std():.3f}\")\n",
    "    print(f\"Target ROUGE: {df['target_rouge'].mean():.3f} ± {df['target_rouge'].std():.3f}\")\n",
    "    print(f\"Unrelated BLEU: {df['unrelated_bleu'].mean():.3f} ± {df['unrelated_bleu'].std():.3f}\")\n",
    "    print(f\"Unrelated ROUGE: {df['unrelated_rouge'].mean():.3f} ± {df['unrelated_rouge'].std():.3f}\")\n",
    "    \n",
    "    # Check if concept vectors are working\n",
    "    target_degradation = 1 - df['target_bleu'].mean()\n",
    "    unrelated_degradation = 1 - df['unrelated_bleu'].mean()\n",
    "    \n",
    "    print(f\"\\n📊 VALIDATION ANALYSIS:\")\n",
    "    print(f\"Target knowledge degradation: {target_degradation:.3f}\")\n",
    "    print(f\"Unrelated knowledge degradation: {unrelated_degradation:.3f}\")\n",
    "    \n",
    "    if target_degradation > unrelated_degradation * 1.5:\n",
    "        print(\"✅ SUCCESS: Concept vectors appear to encode specific knowledge!\")\n",
    "        print(\"   Target concepts are more affected by noise than unrelated concepts.\")\n",
    "    elif target_degradation > unrelated_degradation * 1.1:\n",
    "        print(\"⚠️  PARTIAL: Some evidence of concept-specific encoding.\")\n",
    "        print(\"   Consider adjusting noise scale or testing more concepts.\")\n",
    "    else:\n",
    "        print(\"❌ INCONCLUSIVE: No clear evidence of concept-specific encoding.\")\n",
    "        print(\"   This could be due to synthetic data or model limitations.\")\n",
    "    \n",
    "    # Display detailed results\n",
    "    print(\"\\nDetailed results:\")\n",
    "    for _, row in df.iterrows():\n",
    "        print(f\"{row['concept']} (L{row['layer']}, D{row['dimension']}):\")\n",
    "        print(f\"  Target: BLEU={row['target_bleu']:.3f}, ROUGE={row['target_rouge']:.3f}\")\n",
    "        print(f\"  Unrelated: BLEU={row['unrelated_bleu']:.3f}, ROUGE={row['unrelated_rouge']:.3f}\")\n",
    "    \n",
    "    # Save results\n",
    "    results_file = os.path.join(BASE_DIR, 'gemma_concept_validation_results.json')\n",
    "    with open(results_file, 'w') as f:\n",
    "        json.dump(gemma_results, f, indent=2)\n",
    "    print(f\"\\n✓ Results saved to {results_file}\")\n",
    "else:\n",
    "    print(\"No results to analyze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9573eb6d",
   "metadata": {},
   "source": [
    "## Simple Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09037dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Plot saved to /Users/daniel/Desktop/ConceptVectors/gemma_concept_validation_plot.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Simple bar plot of results\n",
    "if gemma_results:\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # BLEU scores\n",
    "    concepts = [r['concept'] for r in gemma_results]\n",
    "    target_bleu = [r['target_bleu'] for r in gemma_results]\n",
    "    unrelated_bleu = [r['unrelated_bleu'] for r in gemma_results]\n",
    "    \n",
    "    x = range(len(concepts))\n",
    "    ax1.bar([i - 0.2 for i in x], target_bleu, 0.4, label='Target QA', color='lightcoral')\n",
    "    ax1.bar([i + 0.2 for i in x], unrelated_bleu, 0.4, label='Unrelated QA', color='lightblue')\n",
    "    ax1.set_xlabel('Concepts')\n",
    "    ax1.set_ylabel('BLEU Score')\n",
    "    ax1.set_title('BLEU Scores After Adding Noise (Gemma-1.1-1B)')\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(concepts, rotation=45, ha='right')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # ROUGE scores\n",
    "    target_rouge = [r['target_rouge'] for r in gemma_results]\n",
    "    unrelated_rouge = [r['unrelated_rouge'] for r in gemma_results]\n",
    "    \n",
    "    ax2.bar([i - 0.2 for i in x], target_rouge, 0.4, label='Target QA', color='lightcoral')\n",
    "    ax2.bar([i + 0.2 for i in x], unrelated_rouge, 0.4, label='Unrelated QA', color='lightblue')\n",
    "    ax2.set_xlabel('Concepts')\n",
    "    ax2.set_ylabel('ROUGE-L Score')\n",
    "    ax2.set_title('ROUGE-L Scores After Adding Noise (Gemma-1.1-1B)')\n",
    "    ax2.set_xticks(x)\n",
    "    ax2.set_xticklabels(concepts, rotation=45, ha='right')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save plot\n",
    "    plot_file = os.path.join(BASE_DIR, 'gemma_concept_validation_plot.png')\n",
    "    plt.savefig(plot_file, dpi=150, bbox_inches='tight')\n",
    "    print(f\"✓ Plot saved to {plot_file}\")\n",
    "    \n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No results to visualize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60129b89",
   "metadata": {},
   "source": [
    "## Optional: Test with LLaMA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdd3a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this if you have sufficient resources and want to compare\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"OPTIONAL: LLaMA MODEL TESTING\")\n",
    "print(\"=\"*50)\n",
    "print(\"Uncomment and run the following cells if you want to test LLaMA as well.\")\n",
    "print(\"This requires more resources and may take longer.\")\n",
    "\n",
    "# Uncomment the following code if you want to test LLaMA:\n",
    "# Load LLaMA model and tokenizer\n",
    "# print(f\"Loading LLaMA model: {LLAMA_MODEL_NAME}\")\n",
    "# print(\"This may take a few minutes...\")\n",
    "# \n",
    "# try:\n",
    "#     llama_model = AutoModelForCausalLM.from_pretrained(\n",
    "#         LLAMA_MODEL_NAME,\n",
    "#         torch_dtype=torch.bfloat16 if DEVICE == 'cuda' else torch.float32,\n",
    "#         device_map='auto' if DEVICE == 'cuda' else None,\n",
    "#         trust_remote_code=True\n",
    "#     )\n",
    "#     \n",
    "#     llama_tokenizer = AutoTokenizer.from_pretrained(LLAMA_MODEL_NAME)\n",
    "#     llama_tokenizer.pad_token = llama_tokenizer.eos_token\n",
    "#     llama_tokenizer.padding_side = \"left\"\n",
    "#     \n",
    "#     if DEVICE == 'cpu':\n",
    "#         llama_model = llama_model.to('cpu')\n",
    "#     \n",
    "#     print(f\"✓ LLaMA model loaded successfully on {llama_model.device}\")\n",
    "#     \n",
    "# except Exception as e:\n",
    "#     print(f\"Error loading LLaMA model: {e}\")\n",
    "#     llama_model = None\n",
    "#     llama_tokenizer = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f643fc",
   "metadata": {},
   "source": [
    "## Next Steps and Summary\n",
    "\n",
    "### 🎉 What We Accomplished\n",
    "\n",
    "This notebook successfully demonstrates concept validation using the lightweight **Gemma-1.1-1B-it** model, which is ideal for local execution with minimal hardware requirements.\n",
    "\n",
    "### 🔍 Key Findings\n",
    "\n",
    "- **System Assessment**: Automatically detects your hardware capabilities\n",
    "- **Model Selection**: Chooses appropriate model based on available resources\n",
    "- **Concept Testing**: Validates whether adding noise to specific dimensions affects related knowledge\n",
    "- **Synthetic Concepts**: Uses common knowledge concepts (capitals, math, colors) for testing\n",
    "\n",
    "### 📊 Expected Results\n",
    "\n",
    "- **Target QA scores should decrease** when noise is added to the relevant concept vector\n",
    "- **Unrelated QA scores should remain stable** (closer to original)\n",
    "- This pattern validates that concept vectors encode specific knowledge\n",
    "\n",
    "### 🚀 Future Improvements\n",
    "\n",
    "1. **Real Concept Data**: Replace synthetic concepts with actual concept vectors extracted from the model\n",
    "2. **More Concepts**: Test with a larger variety of concepts\n",
    "3. **Noise Sensitivity**: Experiment with different noise scales (0.05, 0.1, 0.2, 0.5)\n",
    "4. **Layer Analysis**: Test concepts at different layers to understand representation depth\n",
    "5. **Comparison**: Compare results between Gemma and larger models like LLaMA\n",
    "\n",
    "### 💡 Model Recommendations\n",
    "\n",
    "- **Gemma-1.1-1B-it**: Perfect for local testing, fast inference, low memory usage\n",
    "- **LLaMA-7B**: Use if you have >14GB GPU/RAM and want higher quality responses\n",
    "- **Cloud Options**: Consider Google Colab or AWS if local resources are insufficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4687ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "if 'model' in locals() and model is not None:\n",
    "    del model\n",
    "if 'tokenizer' in locals() and tokenizer is not None:\n",
    "    del tokenizer\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "print(\"✓ Models removed from memory\")\n",
    "\n",
    "# Print final summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXPERIMENT COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*60)\n",
    "if gemma_results:\n",
    "    print(f\"✓ Tested {len(gemma_results)} concepts with Gemma-1.1-1B model\")\n",
    "    print(f\"✓ Results saved to gemma_concept_validation_results.json\")\n",
    "    print(f\"✓ Visualization saved to gemma_concept_validation_plot.png\")\n",
    "else:\n",
    "    print(\"⚠️  No results generated - check model loading and data\")\n",
    "print(\"\\nThe lightweight Gemma model makes concept validation experiments\")\n",
    "print(\"accessible on local hardware with minimal resource requirements.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conceptvectors",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
