model_family: llama2-7b #olmo-7b
model_path: /U_PZL2023ZZ0005/jhyu/Llama-2-7b-chat-hf
data_path:  /home/yihuaihong/Unlearn_Harry_Potter/ConceptMap/ConceptMap_data
results_save_path: /U_PZL2023ZZ0005/yhhong/unlearn_results/npo_kl
save_dir: ${results_save_path}/1GPU_${forget_loss}_${lr}_${split}_epoch${num_epochs}_batch${batch_size}_accum${gradient_accumulation_steps}_beta${beta}_ref${ref_policy}_eval${eval_steps}_seed${seed}_${run_index}


LoRA:
  r: 0
  alpha: 32
  dropout: 0.05

lr: 5e-5 #5e-4  lr should be bigger on Niddle
split: wikipedia #wikipedia, pretraining_data
batch_size: 4
gradient_accumulation_steps: 4
gradient_checkpointing: True  #gradient_checkpointing is banned for olmo-7b
num_epochs: 10
forget_loss: npo  # type: grad_ascent, grad_diff, npo, npo_grad_diff, npo_KL, dpo
ft_type: Full #Full, Sparse, MEMIT, Niddle,
loss_threshold: -50

npo_coeff: 1.0
grad_diff_coeff: 1.0
KL_coeff: 1.0
ref_policy: fine_tuned
beta: 0.1
weight_decay: 0.01

seed: 999
run_index: 1
overwrite_dir: True
eval_steps: 1000000000
warmup_steps: steps_per_epoch

